{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrhythmia Prediction Demo\n",
    "\n",
    "Electrocardiograms (ECG) are records of the electrical activity of the heart gathered from electrodes placed on the skin. They are commonly used for medical monitoring and diagnosis.\n",
    "\n",
    "This ECG demo is based on the model developed by the [Stanford ML group](https://stanfordmlgroup.github.io/projects/ecg2/) using the [PhysioNet 2017 challenge dataset](https://www.physionet.org/content/challenge-2017/1.0.0/).  The [GitHub repository](https://github.com/awni/ecg) contains the original code and resources for training models.\n",
    "\n",
    "![Example ECG](figures/A00150.gif) \n",
    "\n",
    "Awni Y Hannun, Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H Ti-son, Codie Bourn, Mintu P Turakhia, and Andrew Y Ng. Cardiologist-level arrhythmia  detection  and  classification  in  ambulatory electrocardiograms using a deep neural network. Nature Medicine, 25(1):65, 2019. https://www.nature.com/articles/s41591-018-0268-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Running the inference requires Keras and serveral other packages to be installed. Run the following cells to ensure that all dependencies are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Installing requirements\")\n",
    "!python3 -m pip --no-cache-dir install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, os.path.join(Path.home(), 'Reference-samples/iot-devcloud'))\n",
    "from demoTools.demoutils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as ani\n",
    "import numpy as np\n",
    "import scipy.stats as sst\n",
    "import scipy.io as sio\n",
    "from IPython.display import HTML\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "This network is used to detect arrhythmias from ECG time series data. The model was trained using the PhysioNet Computing in Cardiology Challenge 2017 (CINC17) dataset, which has four distinct classes which are as follows:\n",
    "\n",
    "N - normal sinus rhythm\n",
    "\n",
    "A - atrial fibrillation (AF)\n",
    "\n",
    "O - an alternative rhythm\n",
    "\n",
    "~ - too noisy to be classified\n",
    "\n",
    "Although this dataset only has four distinct classifications for the ECG records, it is possible to train the model to distinguish between different types of arrhythmias if labels are provided to distinguish between different types.\n",
    "\n",
    "Both the Keras and the OpenVINO models will be run using a subset of the original test data that excludes any examples below a specified length. Although the Keras model can take inputs of variable size, we use the same input set as the OpenVINO examples for consistency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Information\n",
    "\n",
    "In this section we will see examples of the four different classes of arrhythmias and some of their distinguishing characteristics.\n",
    "\n",
    "The code below will convert the time series data into short animations which illustrate what each class looks like. Note that processing can take some time (~1-2 mins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ecg_animation(filename, y):\n",
    "    step_size = 12\n",
    "    x_lim = 1800\n",
    "    scale_factor = 7\n",
    "    num_frames = x_lim // step_size\n",
    "    x =  range(0,(x_lim*scale_factor),scale_factor)\n",
    "    y_max = 1.11*max(np.amax(y), abs(np.amin(y)))\n",
    "\n",
    "    plt.ioff()\n",
    "    \n",
    "    #set up the figure\n",
    "    fig, ax = plt.subplots()\n",
    "    line, = ax.plot([], [], color='k')\n",
    "    \n",
    "    ax.tick_params(axis=\"both\", which=\"both\", length=0.0, labelbottom=False, labelleft=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # Create the grid with 4x4 grid squares\n",
    "    aspect_ratio = 4200 / (2*y_max)\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(400))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(400 / aspect_ratio))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    ax.grid(which='major', linestyle='-', axis='both')\n",
    "    ax.grid(which='minor', linewidth='0.5', axis='both', color='lightgray')\n",
    "\n",
    "    # Settings for figure size\n",
    "    ax.set_xlim(1, x_lim*scale_factor)\n",
    "    ax.set_ylim(-y_max, y_max)\n",
    "    fig.set_figheight(4.5)\n",
    "    fig.set_figwidth(13.5)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    canvas_width, canvas_height = fig.canvas.get_width_height()\n",
    "\n",
    "    def update(num):\n",
    "        offset = int(num // (x_lim / step_size)) + 2\n",
    "        index = int(num % (x_lim / step_size))\n",
    "        line.set_data(x[:(step_size*index)], y[(x_lim*offset):(x_lim*offset+step_size*index)])\n",
    "\n",
    "    # Open an ffmpeg process\n",
    "    cmdstring = ('ffmpeg', \n",
    "                 '-y', '-r', '25', # 25fps\n",
    "                 '-s', '%dx%d' % (canvas_width, canvas_height), # size of image string\n",
    "                 '-pix_fmt', 'argb', # format\n",
    "                 '-f', 'rawvideo',  '-i', '-', # tell ffmpeg to expect raw video from the pipe\n",
    "                 '-preset', 'ultrafast',\n",
    "                 '-vcodec', 'h264', 'figures/' + filename) # output encoding\n",
    "    p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE)\n",
    "\n",
    "    # Draw frames and write to the pipe\n",
    "    for frame in range(num_frames):\n",
    "        # draw the frame\n",
    "        update(frame)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        # extract the image as an ARGB string\n",
    "        string = fig.canvas.tostring_argb()\n",
    "\n",
    "        # write to pipe\n",
    "        p.stdin.write(string)\n",
    "\n",
    "    # Finish up\n",
    "    p.communicate()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Sinus Rhythm\n",
    "\n",
    "Normal ECG rhythms consist of four distinct sections: P wave, QRS complex, T wave, and U wave.\n",
    "\n",
    "<figure>\n",
    "<img src=\"figures/EKG_info.svg\" height=40%, width=40%/>\n",
    "<figcaption style=\"text-align:center\"><a href=\"https://commons.wikimedia.org/wiki/File:EKG_Complex_en.svg\" title=\"via Wikimedia Commons\">ECG Complex</a> [<a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA</a>]</figcaption>\n",
    "</figure>\n",
    "\n",
    "The P wave represents atrial depolarization.  \n",
    "The QRS complex represents ventricular depolarization.  \n",
    "The T wave represents ventricular repolarization.  \n",
    "The U wave represents papillary muscle repolarization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_normal = sio.loadmat('/data/ecg/training/A00001.mat')['val'].squeeze()\n",
    "\n",
    "create_ecg_animation('ecg_normal.mp4', ecg_normal)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_normal.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atrial Fibrilation\n",
    "\n",
    "Atrial fibrilation is usually distinguished by irregular intervals between heart beats, rapid heart rate, and lack of a P wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_af = sio.loadmat('/data/ecg/training/A00004.mat')['val'].squeeze()\n",
    "\n",
    "create_ecg_animation(\"ecg_af.mp4\", ecg_af)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_af.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Rhythm\n",
    "\n",
    "For this dataset, all non-AF abnormal rhythms are classified as other rhythms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_other = sio.loadmat('/data/ecg/training/A00077.mat')['val'].squeeze()\n",
    "\n",
    "create_ecg_animation(\"ecg_other.mp4\", ecg_other)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_other.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too noisy to be classified\n",
    "\n",
    "This final classification includes data that has too much noise to have any distinguishable pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_undef = sio.loadmat('/data/ecg/training/A01246.mat')['val'].squeeze()\n",
    "\n",
    "create_ecg_animation(\"ecg_undef.mp4\", ecg_undef)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_undef.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Prediction Using Keras\n",
    "\n",
    "In this section we will run all of the sample data through Keras using a Tensorflow backend. After getting predictions from the model, we will compare it to the ground truth labels to measure accuracy. The inference it done by running the [keras_inference.py](./python/keras_inference.py) script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 python/keras_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Keras Model for OpenVINO\n",
    "\n",
    "Next we will run inference using OpenVINO. In order to make the model usable for OpenVINO we first need to convert the model from its original format to a tensorflow frozen protobuf format, which then can be run through the OpenVINO model optimizer to produce an Intermediate Representation that is usable by OpenVINO. The script can be found at [tensorflow_conversion.py](./python/tensorflow_conversion.py)\n",
    "\n",
    "\n",
    ".hdf5 (keras) -> pb (tensorflow) -> IR (OpenVINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 python/tensorflow_conversion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For conversion to the OpenVINO Intermediate Representation (IR) we need to specify the size of the input. We also specify the data type as FP16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "--input_model models/output_graph.pb                                   \\\n",
    "--output_dir models/                                                   \\\n",
    "--input_shape \"[1,8960,1]\"                                             \\\n",
    "--data_type FP16                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference Using OpenVINO\n",
    "\n",
    "The OpenVINO model only takes input of a specific size so we truncate all of the data that is above that size before feeding it into the model. The script for running the OpenVINO inference can be found at [openvino_inference.py](./python/openvino_inference.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 python/openvino_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Results\n",
    "\n",
    "The following cell creates a visualization to show the results of the network's predictions. Different colors are used to represent the predicted class (N - blue, A - red, O - yellow, ~ - gray) with a score for the confidence in the prediction at the bottom of each section. The final predicted class is determined by taking the most commonly predicted class across all of the time slices for the sample. Only the first 20 time slices are shown below to allow for greater visual clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(sample, prediction, probabilities, actual):\n",
    "    data_points = 256*20\n",
    "    \n",
    "    predicted = sst.mode(prediction)[0][0]\n",
    "    y = sio.loadmat('/data/ecg/training/' + sample)['val'].squeeze()[:data_points] #[3840:5640]\n",
    "    \n",
    "    x =  range(0,data_points)\n",
    "    y_max = 1.11*max(np.amax(y), abs(np.amin(y)))\n",
    "    \n",
    "    #set up the figure\n",
    "    fig, ax = plt.subplots()\n",
    "    line, = ax.plot(x, y, color='k')\n",
    "    ax.title.set_text(sample + ', Predicted Class - ' + predicted + ', Actual Class - ' + actual)\n",
    "    \n",
    "    ax.tick_params(axis=\"both\", which=\"both\", length=0.0, labelbottom=False, labelleft=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # Add axis lines\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(256))\n",
    "    ax.grid(which='major', linestyle='-', axis='x', color='k')\n",
    "\n",
    "    # Settings for figure size\n",
    "    ax.set_xlim(1, data_points)\n",
    "    ax.set_ylim(-y_max, y_max)\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(12)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    i = 0\n",
    "    for label, prob in zip(prediction[:20], probabilities[:20]):\n",
    "        colors = {'A' : 'r', 'N' : 'b', 'O' : 'y', '~': 'k'}\n",
    "        plt.text((i+.2)*256, -y_max, '%.3f' % prob)\n",
    "        plt.axvspan(i*256, (i+1)*256, facecolor=colors[label], alpha=prob/3)\n",
    "        i += 1\n",
    "        \n",
    "    plt.show(fig)    \n",
    "    plt.close(fig)\n",
    "\n",
    "def show_all_predictions():\n",
    "    with open('results/predictions.json', 'r') as preds:\n",
    "        preds = json.load(preds)\n",
    "        items = list(preds.items())\n",
    "        list(map(lambda x: visualize_result(x[0], x[1]['data'], x[1]['prob'], x[1]['actual']), items))\n",
    "\n",
    "def show_prediction_subset(items):\n",
    "    with open('results/predictions.json', 'r') as preds:\n",
    "        preds = json.load(preds)\n",
    "        list(map(lambda x: visualize_result(x, preds[x]['data'], preds[x]['prob'], preds[x]['actual']), items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions with accurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_prediction_subset(['A02261', 'A06779', 'A00593', 'A02479'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions with lower confidence or inaccurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_prediction_subset(['A00722', 'A04222', 'A08010', 'A08525'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) View all of the evaluation data\n",
    "\n",
    "Run the follwing cell to display all 300 of the samples and the predictions given by the model. Due to the number of samples, it may take a couple minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the edge\n",
    "\n",
    "All the code up to this point has been run on a development node based on an Intel Xeon Scalable processor. We will run the workload on other edge compute nodes represented in the IoT DevCloud by submitting the corresponding non-interactive jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job.\n",
    "\n",
    "The job file is written in Bash, and will be executed directly on the edge compute node. For this example, we have written the job file for you in the notebook. It performs the classification using the script [inference.py](./python/inference.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile prediction.sh\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "mkdir -p $1\n",
    "OUTPUT_DIR=$1\n",
    "DEVICE=$2\n",
    "\n",
    "if [ \"$DEVICE\" = \"HETERO:FPGA,CPU\" ]; then\n",
    "  # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "  source /opt/intel/init_openvino.sh\n",
    "  aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/2019R3_PV_PL1_FP16_MobileNet_Clamp.aocx\n",
    "fi\n",
    "\n",
    "python3 python/inference.py -d ${DEVICE} -o ${OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How jobs are submitted into the queue\n",
    "\n",
    "Now that we have the job script, we can submit the jobs to edge compute nodes. In the IoT DevCloud, you can do this using the `qsub` command.\n",
    "We can submit the job to 6 different types of edge compute nodes simultaneously or just one node at at time.\n",
    "\n",
    "There are five options of `qsub` command that we use for this:\n",
    "- `-l` : this option lets us select the number and the type of nodes using `nodes={node_count}:{property}`. \n",
    "- `-F` : this option lets us send arguments to the bash script. \n",
    "- `-N` : this option lets us name the job so that it is easier to distinguish between them.\n",
    "- `-o` : this option lets us determine the path to be used for the standard output stream.\n",
    "- `-e` : this option lets us determine the path to be used for the standard error stream.\n",
    "\n",
    "\n",
    "The `-F` flag is used to pass in arguments to the job script.\n",
    "The [prediction.sh](prediction.sh) script takes in 2 arguments:\n",
    "1. the path to the directory for the output video and performance stats\n",
    "2. targeted device (e.g. CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "\n",
    "The job scheduler will use the contents of `-F` flag as the argument to the job script.\n",
    "\n",
    "If you are curious to see the available types of nodes on the IoT DevCloud, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pbsnodes | grep compnode | awk '{print $3}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the properties describe the node, and number on the left is the number of available nodes of that architecture.\n",
    "\n",
    "### Job queue submission\n",
    "\n",
    "The output of the cell is the `JobID` of your job, which you can use to track progress of a job.\n",
    "\n",
    "**Note** You can submit all the jobs at once or follow one at a time. \n",
    "\n",
    "After submission, they will go into a queue and run as soon as the requested compute resources become available. \n",
    "(tip: **shift+enter** will run the cell and automatically move you to the next cell. So you can hit **shift+enter** multiple times to quickly run multiple cells).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with an Intel Core CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel \n",
    "    Core i5-6500TE</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_core = !qsub prediction.sh -l nodes=1:idc001skl:i5-6500te -F \"results/core/ CPU\" -N arrhythmia_core -e results/core/ -o results/core/   \n",
    "print(job_id_core[0]) \n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('./logs', job_id_core[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_core[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with an 8th Generation Intel Core CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/8th-gen-core-dev-kit\">UP Xtreme Edge Compute Enabling Kit\n",
    "    </a> edge node with a low power <a \n",
    "    href=\"https://ark.intel.com/content/www/us/en/ark/products/193554/intel-core-i7-8665ue-processor-8m-cache-up-to-4-40-ghz.html\">Intel \n",
    "    Core i7-8865UE</a>. The inference workload will run on the CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_core2 = !qsub prediction.sh -l nodes=1:idc014upxa10fx1:upx-edgei7 -F \"results/core2/ CPU\" -N arrhythmia_core2 -e results/core2/ -o results/core2/\n",
    "print(job_id_core[0]) \n",
    "#Progress indicators\n",
    "if job_id_core2:\n",
    "    progressIndicator('./logs', job_id_core2[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_core2[0]+'.txt', \"Inference\", 0, 100)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel Xeon CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel \n",
    "    Xeon Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_xeon = !qsub prediction.sh -l nodes=1:idc007xv5:intel-xeon -F \"results/xeon/ CPU\" -N arrhythmia_xeon -e results/xeon/ -o results/xeon/\n",
    "print(job_id_xeon[0]) \n",
    "#Progress indicators\n",
    "if job_id_xeon:\n",
    "    progressIndicator('./logs', job_id_xeon[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_xeon[0]+'.txt', \"Inference\", 0, 100)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Core CPU and using the onboard Intel® GPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel® Core i5-6500TE</a>. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_gpu = !qsub prediction.sh -l nodes=1:tank-870:i5-6500te:intel-hd-530 -F \"results/gpu/ GPU\" -N arrhythmia_gpu -e results/gpu/ -o results/gpu/\n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('./logs', job_id_gpu[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_gpu[0]+'.txt', \"Inference\", 0, 100)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with UP Squared Grove IoT Development Kit (UP2)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/up-squared-grove-dev-kit\">UP Squared Grove IoT Development Kit</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/96488/Intel-Atom-x7-E3950-Processor-2M-Cache-up-to-2-00-GHz-\">Intel® Atom® x7-E3950 Processor</a>. The inference  workload will run on the integrated Intel® HD Graphics 505 card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_up2 = !qsub prediction.sh -l nodes=1:up-squared -F \"results/up2/ GPU\" -N arrhythmia_up2 -e results/up2/ -o results/up2/\n",
    "print(job_id_up2[0]) \n",
    "#Progress indicators\n",
    "if job_id_up2:\n",
    "    progressIndicator('./logs', job_id_up2[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_up2[0]+'.txt', \"Inference\", 0, 100)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with  IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a> . The inference workload will run on the <a href=\"https://www.ieiworld.com/mustang-f100/en/\"> IEI Mustang-F100-A10 </a> card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_fpga = !qsub prediction.sh -l nodes=1:idc003a10:iei-mustang-f100-a10 -F \"results/fpga/ HETERO:FPGA,CPU\" -N arrhythmia_fpga -e results/fpga/ -o results/fpga/\n",
    "print(job_id_fpga[0]) \n",
    "#Progress indicators\n",
    "if job_id_fpga:\n",
    "    progressIndicator('./logs', job_id_fpga[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_fpga[0]+'.txt', \"Inference\", 0, 100)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the jobs are done\n",
    "\n",
    "To check on the jobs that were submitted, use the `qstat` command.\n",
    "\n",
    "We have created a custom Jupyter widget  to get live qstat update.\n",
    "Run the following cell to bring it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the jobs you have submitted (referenced by `Job ID` that gets displayed right after you submit the job in step 2.3).\n",
    "There should also be an extra job in the queue \"jupyterhub\": this job runs your current Jupyter Notebook session.\n",
    "\n",
    "The 'S' column shows the current status. \n",
    "- If it is in Q state, it is in the queue waiting for available resources. \n",
    "- If it is in R state, it is running. \n",
    "- If the job is no longer listed, it means it is completed.\n",
    "\n",
    "**Note**: Time spent in the queue depends on the number of users accessing the edge nodes. Once these jobs begin to run, they should take from 10-40 seconds to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Wait!***\n",
    "\n",
    "Please wait for the inference jobs to complete before proceeding to the next step.\n",
    "\n",
    "## Compare Results\n",
    "\n",
    "The running time of each inference task is recorded in `results/{arch}/stats_{job_id}.txt` and the output of the inference is stored at `results/{arch}/{job_name}.o{job_id}`. Run the cell below to plot the results of all jobs side-by-side. Lower values mean better performance. Keep in mind that some architectures are optimized for the highest performance, others for low power or other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE\\nCPU'),\n",
    "             ('core2', 'Intel Core\\ni7-8865UE\\nCPU'),\n",
    "             ('xeon', 'Intel Xeon\\nE3-1268L v5\\nCPU'),\n",
    "             ('gpu', ' Intel Core\\ni5-6500TE\\nGPU'),\n",
    "             ('up2', 'Intel Atom\\nx7-E3950\\nUP2/GPU'),\n",
    "             ('fpga', ' IEI Mustang\\nF100-A10\\nFPGA')]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        stats_list.append(('results/' + arch + '/stats_'+vars()['job_id_'+arch][0]+'.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "plt.ion()\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, miliseconds', 'Inference Engine Processing Time Per Sample', 'time' )"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
