{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrocardiogram (ECG) Arrhythmia Detection Demo (WIP)\n",
    "\n",
    "Electrocardiograms are records of the electrical activity of the heart gathered from electrodes placed on the skin. They are commonly used for medical monitoring and diagnosis.\n",
    "\n",
    "This ECG demo is based on the model developed by the [Stanford ML group](https://stanfordmlgroup.github.io/projects/ecg2/) using the [PhysioNet 2017 challenge dataset](https://www.physionet.org/content/challenge-2017/1.0.0/).  The [GitHub repository](https://github.com/awni/ecg) contains the original code and resources for training models.\n",
    "\n",
    "![Example ECG](figures/A00150.gif) \n",
    "\n",
    "Awni Y Hannun, Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H Ti-son, Codie Bourn, Mintu P Turakhia, and Andrew Y Ng. Cardiologist-levelarrhythmia  detection  and  classification  in  ambulatory  electrocardiogramsusing a deep neural network.Nature Medicine, 25(1):65, 2019. https://www.nature.com/articles/s41591-018-0268-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements and Imports\n",
    "Running the inference requires Keras and serveral other packages to be installed. Run the following cells to ensure that all dependencies are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Installing requirements\")\n",
    "!python3 -m pip --no-cache-dir install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, os.path.join(Path.home(), 'Reference-samples/iot-devcloud'))\n",
    "from demoTools.demoutils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as ani\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from IPython.display import HTML\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Problem and Model\n",
    "\n",
    "This network is used to detect arrhythmias from ECG time series data. The model was trained using the PhysioNet Computing in Cardiology Challenge 2017 (CINC17) dataset, which has four distinct classes which are as follows:\n",
    "\n",
    "N - normal sinus rhythm\n",
    "\n",
    "A - atrial fibrillation (AF)\n",
    "\n",
    "O - an alternative rhythm\n",
    "\n",
    "~ - too noisy to be classified\n",
    "\n",
    "Although this dataset only has four distinct classifications for the ECG records, it is possible to train the model to distinguish between different types of arrhythmias if labels are provided to distinguish between different types.\n",
    "\n",
    "Both the Keras and the OpenVINO models will be run using a subset of the original test data that excludes any examples below a specified length. Although the Keras model can take inputs of variable size, we use the same input set as the OpenVINO examples for consistency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Information\n",
    "\n",
    "In this section we will see examples of the four different classes of arrhythmias and some of their distinguishing characteristics.\n",
    "\n",
    "The code below will convert the time series data into short animations which illustrate what each class looks like. Note that processing can take some time (~1-2 mins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ecg_graph(filename, y):\n",
    "    step_size = 12\n",
    "    x_lim = 1800\n",
    "    scale_factor = 7\n",
    "    num_frames = x_lim // step_size\n",
    "    x =  range(0,(x_lim*scale_factor),scale_factor)\n",
    "    y_max = 1.11*max(np.amax(y), abs(np.amin(y)))\n",
    "    \n",
    "    plt.ioff()\n",
    "    \n",
    "    #set up the figure\n",
    "    fig, ax = plt.subplots()\n",
    "    line, = ax.plot([], [], color='k')\n",
    "    \n",
    "    ax.tick_params(axis=\"both\", which=\"both\", length=0.0, labelbottom=False, labelleft=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    # Create the grid with 4x4 grid squares\n",
    "    aspect_ratio = 4200 / (2*y_max)\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(400))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(400 / aspect_ratio))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    ax.grid(which='major', linestyle='-', axis='both')\n",
    "    ax.grid(which='minor', linewidth='0.5', axis='both', color='lightgray')\n",
    "\n",
    "    # Settings for figure size\n",
    "    ax.set_xlim(1, x_lim*scale_factor)\n",
    "    ax.set_ylim(-y_max, y_max)\n",
    "    fig.set_figheight(4.5)\n",
    "    fig.set_figwidth(13.5)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    canvas_width, canvas_height = fig.canvas.get_width_height()\n",
    "\n",
    "    def update(num):\n",
    "        offset = int(num // (x_lim / step_size)) + 2\n",
    "        index = int(num % (x_lim / step_size))\n",
    "        line.set_data(x[:(step_size*index)], y[(x_lim*offset):(x_lim*offset+step_size*index)])\n",
    "\n",
    "    # Open an ffmpeg process\n",
    "    cmdstring = ('ffmpeg', \n",
    "                 '-y', '-r', '25', # 25fps\n",
    "                 '-s', '%dx%d' % (canvas_width, canvas_height), # size of image string\n",
    "                 '-pix_fmt', 'argb', # format\n",
    "                 '-f', 'rawvideo',  '-i', '-', # tell ffmpeg to expect raw video from the pipe\n",
    "                 '-preset', 'ultrafast',\n",
    "                 '-vcodec', 'h264', 'figures/' + filename) # output encoding\n",
    "    p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE)\n",
    "\n",
    "    # Draw frames and write to the pipe\n",
    "    for frame in range(num_frames):\n",
    "        # draw the frame\n",
    "        update(frame)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        # extract the image as an ARGB string\n",
    "        string = fig.canvas.tostring_argb()\n",
    "\n",
    "        # write to pipe\n",
    "        p.stdin.write(string)\n",
    "\n",
    "    # Finish up\n",
    "    p.communicate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Sinus Rhythm\n",
    "\n",
    "Normal ECG rhythms consist of four distinct sections: P wave, QRS complex, T wave, and U wave.\n",
    "\n",
    "<figure>\n",
    "<img src=\"figures/EKG_info.svg\" height=40%, width=40%/>\n",
    "<figcaption style=\"text-align:center\"><a href=\"https://commons.wikimedia.org/wiki/File:EKG_Complex_en.svg\" title=\"via Wikimedia Commons\">ECG Complex</a> [<a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA</a>]</figcaption>\n",
    "</figure>\n",
    "\n",
    "The P wave represents atrial depolarization.  \n",
    "The QRS complex represents ventricular depolarization.  \n",
    "The T wave represents ventricular repolarization.  \n",
    "The U wave represents papillary muscle repolarization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_normal = sio.loadmat('data/A00001.mat')['val'].squeeze()\n",
    "\n",
    "\n",
    "create_ecg_graph('ecg_normal.mp4', ecg_normal)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_normal.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atrial Fibrilation\n",
    "\n",
    "This is usually marked by irregular intervals between heart beats, rapid heart rate, and lack of a P wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_af = sio.loadmat('data/A00004.mat')['val'].squeeze()\n",
    "\n",
    "create_ecg_graph(\"ecg_af.mp4\", ecg_af)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_af.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Rhythm\n",
    "\n",
    "For this dataset, all non-AF abnormal rhythms are classified as other rhythms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_other = sio.loadmat('data/A00077.mat')['val'].squeeze()\n",
    "\n",
    "create_ecg_graph(\"ecg_other.mp4\", ecg_other)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_other.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too noisy to be classified\n",
    "\n",
    "This final classification includes data that has too much noise to have any distinguishable pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_undef = sio.loadmat('data/A01246.mat')['val'].squeeze()\n",
    "\n",
    "create_ecg_graph(\"ecg_undef.mp4\", ecg_undef)\n",
    "\n",
    "HTML('''\n",
    "    <video alt=\"test\" controls autoplay loop>\n",
    "        <source src=\"figures/ecg_undef.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Prediction Using Keras\n",
    "\n",
    "In this section we will run all of the sample data through Keras using a Tensorflow backend. After getting predictions from the model, we will compare it to the ground truth labels to measure accuracy. The inference it done by running the [keras_inference.py](./keras_inference.py) script, whose contents are shown in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "from time import time\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import scipy.stats as sst\n",
    "import sklearn.metrics as skm\n",
    "from keras.backend.tensorflow_backend import tf\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "from tqdm import tqdm\n",
    "\n",
    "import load\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "model_path = \"/data/ecg/0.427-0.863-020-0.290-0.899.hdf5\"\n",
    "data_csv = \"./data/reference.csv\"\n",
    "\n",
    "print(\"Loading Dataset\")\n",
    "ecgs, labels = load.load_dataset(data_csv)\n",
    "\n",
    "print(\"Loading Model\")\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "print(\"Starting Inference\")\n",
    "probs = []\n",
    "total_time = 0\n",
    "for x in tqdm(ecgs):\n",
    "    x = load.process_x(x)\n",
    "    start_time = time()\n",
    "    probs.append(model.predict(x))\n",
    "    total_time += (time() - start_time)\n",
    "    \n",
    "print(\"Keras took {} sec for inference\".format(total_time))\n",
    "\n",
    "# The class distribution of the overall dataset\n",
    "prior = [[[0.15448743, 0.66301941, 0.34596848, 0.09691286]]]\n",
    "\n",
    "# Determine the predicted class from the most commonly predicted class \n",
    "preds = []\n",
    "for p in probs:\n",
    "    preds.append(sst.mode(np.argmax(p / prior, axis=2).squeeze())[0][0])\n",
    "\n",
    "# Generate a report with the precision, recall, and f-1 scores for each of the classes\n",
    "report = skm.classification_report(labels, preds, target_names=['A','N','O','~'], digits=3)\n",
    "scores = skm.precision_recall_fscore_support(labels, preds, average=None)\n",
    "\n",
    "print(report)\n",
    "print (\"CINC Average {:3f}\".format(np.mean(scores[2][:3])))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 python/keras_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Keras Model for OpenVINO\n",
    "\n",
    "Next we will run inference using OpenVINO. In order to make the model usable for OpenVINO we first need to convert the model from its original format to a tensorflow frozen protobuf format, which then can be run through the OpenVINO model optimizer to produce an Intermediate Representation that is usable by OpenVINO.\n",
    "\n",
    "\n",
    ".hdf5 (keras) -> pb (tensorflow) -> IR (OpenVINO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "K.clear_session()\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "input_model = '/data/ecg/0.427-0.863-020-0.290-0.899.hdf5'\n",
    "output_model = 'models/output_graph.pb'\n",
    "num_output = 1 \n",
    "\n",
    "model = load_model(input_model)\n",
    "print(model.summary())\n",
    "\n",
    "predictions = [None] * num_output\n",
    "predrediction_node_names = [None] * num_output\n",
    "\n",
    "for i in range(num_output):\n",
    "    predrediction_node_names[i] = 'output_node' + str(i)\n",
    "    predictions[i] = tf.identity(model.outputs[i], \n",
    "    name=predrediction_node_names[i])\n",
    "\n",
    "sess = K.get_session()\n",
    "\n",
    "constant_graph = tf.compat.v1.graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), predrediction_node_names)\n",
    "infer_graph = tf.compat.v1.graph_util.remove_training_nodes(constant_graph) \n",
    "\n",
    "graph_io.write_graph(infer_graph, '.', output_model, as_text=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 python/tensorflow_conversion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For conversion to the OpenVINO Intermediate Representation (IR) we need to specify the size of the input. We also specify the data type as FP16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "--input_model models/output_graph.pb                                   \\\n",
    "--output_dir models/                                                   \\\n",
    "--input_shape \"[1,8960,1]\"                                             \\\n",
    "--data_type FP16                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference Using OpenVINO\n",
    "\n",
    "The OpenVINO model only takes input of a specific size so we truncate all of the data that is above that size before feeding it into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as sst\n",
    "import sklearn.metrics as skm\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "from tqdm import tqdm\n",
    "\n",
    "import load\n",
    "\n",
    "data_csv = \"./data/reference.csv\"\n",
    "\n",
    "print(\"Loading Dataset\")\n",
    "ecgs, labels = load.load_dataset(data_csv)\n",
    "\n",
    "# Load network and add CPU extension\n",
    "ie = IECore()\n",
    "ie.add_extension('/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so',\"CPU\")\n",
    "net = IENetwork(model = './models/output_graph.xml', weights = './models/output_graph.bin')\n",
    "exec_net = ie.load_network(network=net, device_name='CPU')\n",
    "\n",
    "print(\"Starting Inference\")\n",
    "probs_total = []\n",
    "total_time = 0\n",
    "for x in tqdm(ecgs):\n",
    "    x = load.process_x(x)\n",
    "    start_time = time()\n",
    "    res = exec_net.infer(inputs={\"inputs\": x})\n",
    "    total_time += (time() - start_time)\n",
    "    probs = res[\"time_distributed_1/Reshape_1/Softmax\"]\n",
    "    probs_total.append(probs)\n",
    "\n",
    "print(\"OpenVINO took {} sec for inference\".format(total_time))\n",
    "\n",
    "# The class distribution of the overall dataset\n",
    "prior = [[[0.15448743, 0.66301941, 0.34596848, 0.09691286]]]\n",
    "\n",
    "# Determine the predicted class from the most commonly predicted class \n",
    "preds = []\n",
    "for p in probs_total:\n",
    "    preds.append(sst.mode(np.argmax(p / prior, axis=2).squeeze())[0][0])\n",
    "    \n",
    "# Generate a report with the precision, recall, and f-1 scores for each of the classes\n",
    "report = skm.classification_report(labels, preds, target_names=['A','N','O','~'], digits=3)\n",
    "scores = skm.precision_recall_fscore_support(labels, preds, average=None)\n",
    "\n",
    "print(report)\n",
    "print (\"CINC Average {:3f}\".format(np.mean(scores[2][:3])))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 python/openvino_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below should follow the standard layout that all of the other notebooks share.\n",
    "\n",
    "Will need to test on the various hardware platforms to make sure that everything works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the edge\n",
    "\n",
    "All the code up to this point has been run on a development node based on an Intel Xeon Scalable processor. We will run the workload on other edge compute nodes represented in the IoT DevCloud by submitting the corresponding non-interactive jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile prediction.sh\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "DEVICE=$1\n",
    "\n",
    "if [ \"$DEVICE\" = \"HETERO:FPGA,CPU\" ]; then\n",
    "  # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "  source /opt/intel/init_openvino.sh\n",
    "  aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/2019R3_PV_PL1_FP16_MobileNet_Clamp.aocx\n",
    "fi\n",
    "\n",
    "python3 python/inference.py -d ${DEVICE}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View what nodes are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pbsnodes | grep compnode | awk '{print $3}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job queue submission\n",
    "For this demo we only include the CPU and GPU nodes since the layers of the model are not currently supported by the FPGA, MYRIAD, and HDDL OpenVINO plugins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_core = !qsub prediction.sh -l nodes=1:idc001skl:i5-6500te -F \"CPU\" -N arrhythmia_core -e logs/ -o logs/      \n",
    "print(job_id_core[0]) \n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('./logs', job_id_core[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_core[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_xeon = !qsub prediction.sh -l nodes=1:idc007xv5:intel-xeon -F \"CPU\" -N arrhythmia_xeon -e logs/ -o logs/\n",
    "print(job_id_xeon[0]) \n",
    "#Progress indicators\n",
    "if job_id_xeon:\n",
    "    progressIndicator('./logs', job_id_xeon[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_xeon[0]+'.txt', \"Inference\", 0, 100)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_gpu = !qsub prediction.sh -l nodes=1:tank-870:i5-6500te:intel-hd-530 -F \"GPU\" -N arrhythmia_gpu -e logs/ -o logs/\n",
    "print(job_id_gpu[0]) \n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('./logs', job_id_gpu[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_gpu[0]+'.txt', \"Inference\", 0, 100)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_up2 = !qsub prediction.sh -l nodes=1:up-squared -F \"GPU\" -N arrhythmia_up2 -e logs/ -o logs/\n",
    "print(job_id_up2[0]) \n",
    "#Progress indicators\n",
    "if job_id_up2:\n",
    "    progressIndicator('./logs', job_id_up2[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_up2[0]+'.txt', \"Inference\", 0, 100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_fpga = !qsub prediction.sh -l nodes=1:idc003a10:iei-mustang-f100-a10 -F \"HETERO:FPGA,CPU\" -N arrhythmia_fpga -e logs/ -o logs/\n",
    "print(job_id_fpga[0]) \n",
    "#Progress indicators\n",
    "if job_id_fpga:\n",
    "    progressIndicator('./logs', job_id_fpga[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_fpga[0]+'.txt', \"Inference\", 0, 100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_ncs2 = !qsub prediction.sh -l nodes=1:tank-870:i5-6500te:intel-ncs2 -F \"MYRIAD\" -N arrhythmia_ncs2 -e logs/ -o logs/\n",
    "print(job_id_ncs2[0]) \n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('./logs', job_id_ncs2[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_ncs2[0]+'.txt', \"Inference\", 0, 100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_hddlr = !qsub prediction.sh -l nodes=1:tank-870:iei-mustang-v100-mx8 -F \"HDDL\" -N arrhythmia_hddlr -e logs/ -o logs/\n",
    "print(job_id_hddlr[0]) \n",
    "#Progress indicators\n",
    "if job_id_hddlr:\n",
    "    progressIndicator('./logs', job_id_hddlr[0] + '_load.txt', \"Data Loading\", 0, 100)\n",
    "    progressIndicator('./logs', job_id_hddlr[0]+'.txt', \"Inference\", 0, 100)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE\\nCPU'),\n",
    "             ('xeon', 'Intel Xeon\\nE3-1268L v5\\nCPU'),\n",
    "             ('gpu', ' Intel Core\\ni5-6500TE\\nGPU'),\n",
    "             ('up2', 'Intel Atom\\nx7-E3950\\nUP2/GPU'),\n",
    "             ('fpga', ' IEI Mustang\\nF100-A10\\nFPGA'),\n",
    "             ('hddlr', ' IEI Mustang\\nV100-MX8\\nVPU'),\n",
    "             ('ncs2', 'Intel\\nNCS2')]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        stats_list.append(('results/stats_'+vars()['job_id_'+arch][0]+'.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, miliseconds', 'Inference Engine Processing Time Per Sample', 'time' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
