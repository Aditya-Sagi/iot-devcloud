{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Demo: Car Detection\n",
    "\n",
    "This is a sample reference implementation to showcase object detection (car in this case) with single-shot detection (SSD) and Async API.\n",
    "Async API improves the overall frame-rate of the application by not waiting for the inference to complete but continuing to do things on the host while inference accelerator is busy. \n",
    "Specifically, this code demonstrates two parallel inference requests by processing the current frame while the next input frame is being captured. This essentially hides the latency of frame capture.\n",
    "\n",
    "## Overview of how it works\n",
    "At start-up the sample application reads the equivalent of command line arguments and loads a network and image from the video input to the Inference Engine (IE) plugin. \n",
    "A job is submitted to a hardware accelerator (Intel® Core CPU, Intel® HD Graphics GPU, Intel® Core CPU, Intel® Neural Compute Stick 2, Intel® Movidius™ Vision Processing Unit (8x VPU), and Intel® Arria® 10 FPGA.\n",
    "After the inference is completed, the output videos are appropriately stored in the /results directory, which can then be viewed within the Jupyter Notebook instance. \n",
    "\n",
    "## Demonstration objectives\n",
    "* Video as input is supported using **OpenCV**\n",
    "* Inference performed on edge hardware (rather than on the development node hosting this Jupyter notebook)\n",
    "* **OpenCV** provides the bounding boxes, labels and other information\n",
    "* Visualization of the resulting bounding boxes\n",
    "* Demonstrate the Async API in action\n",
    "\n",
    "## How do I modify the above demonstration objectives?\n",
    "Modify the job_config.json file accompanying this example, this file is located in the same directory\n",
    "It is possible to change the raw model used, change the precision of the IR files, or input video and target configurations as desired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Intermediate Representation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Optimizer creates the Intermediate Representation of the model which is the device-agnostic, generic optimization of the model. Caffe\\*, TensorFlow\\*, MXNet\\*, ONNX\\*, and Kaldi\\* models are supported by Model Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **MobileNet-SSD** model for this example. Download the model, specifying the name and output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading raw_models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "... 100%, 28 KB, 47796 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "... 100%, 22605 KB, 21878 KB/s, 1 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd -o raw_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this model to the intermediate representation using Model Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/models/mobilenet-ssd/FP32\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/models/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/models/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 6.98 seconds. \n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--data_type FP32 \\\n",
    "--output_dir models/mobilenet-ssd/FP32 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the FP16 IR version of the model for the calculations on Neural Compute Stick 2 (NCS2) and Visual Processing Unit (VPU); let's create it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/models/mobilenet-ssd/FP16\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/raw_models/public/mobilenet-ssd/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.3.0-375-g332562022\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/models/mobilenet-ssd/FP16/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u19892/Downloads/i360Demo/iot-devcloud/python/demos/object-detection-python/models/mobilenet-ssd/FP16/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 5.57 seconds. \n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--data_type FP16 \\\n",
    "--output_dir models/mobilenet-ssd/FP16 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and configuration file for widget management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qarpo\n",
    "import json\n",
    "with open('job_config.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display available options for Intel® Edge compute hardware and acceleration,  \n",
    "## Display results and performance summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbc2a9314d549b5b2d4ec0e7de7c837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='Target node'), Select(layout=Layout(width='fixed'), options=('Selec…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d273e9b0aed439285a1b15253a17e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5535c148d3134984abbf6c04f93dd478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='No jobs submitted yet'), Tab(), Button(button_style='info', description='Plot resul…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "job_interface = qarpo.Interface(data)\n",
    "job_interface.displayUI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
